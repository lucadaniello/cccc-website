---
title: "plotSuboptimalFits()"
format:
  html:
    toc: true
    toc-depth: 3
page-layout: full
---

**Visualize Smoothed Curves for Quality Assessment**

The `plotSuboptimalFits()` function creates visual comparisons of raw and smoothed keyword frequency trajectories. It helps you assess how well your chosen smoothing parameters perform across different types of keywords in your corpus.

---

## üîπ Function Definition

```r
plotSuboptimalFits(
  data,
  opt_res,
  n_curves = 9,
  show_zone = FALSE,
  graph = FALSE
)
```

---

## üéØ Purpose

After selecting optimal smoothing parameters with `optimalSmoothing()`, it's crucial to **visually validate** that the smoothing works well across your entire corpus. This function helps you:

1. **Assess smoothing quality** ‚Äî See how well smoothed curves capture underlying trends
2. **Detect overfitting/undersmoothing** ‚Äî Identify cases where smoothing is too aggressive or too weak
3. **Evaluate representativeness** ‚Äî Check performance across different keyword types
4. **Compare raw vs. smoothed** ‚Äî Understand what information is retained vs. filtered
5. **Identify problematic cases** ‚Äî Find keywords that may need special treatment
6. **Build confidence** ‚Äî Validate that parameters work well before applying to full corpus
7. **Create publication figures** ‚Äî Generate high-quality visualizations of smoothing results

The function intelligently samples keywords across the **residual distribution** to show a representative range of smoothing performance.

---

## üßÆ How It Works

### RMS Residual Sampling

The function computes **Root Mean Square (RMS)** residuals for all keywords:

```
RMS = ‚àö(Œ£(observed - smoothed)¬≤ / n)
```

Then selects `n_curves` keywords distributed across the RMS range:
- **Low RMS**: Keywords where smoothing fits very well
- **Medium RMS**: Typical smoothing performance
- **High RMS**: Keywords with more complex patterns or poor fits

This ensures you see the **full spectrum** of smoothing behavior, not just the best cases.

---

## ‚öôÔ∏è Arguments

| Argument | Type | Default | Description |
|----------|------|---------|-------------|
| **data** | List | *required* | A list object returned by `importData()` or `normalization()`, containing the TDM and corpus metadata. |
| **opt_res** | List | *required* | The optimal smoothing configuration returned by `optimalSmoothing()`, including spline degree (`m_opt`), penalty type (`penalty_opt`), and lambda (`lambda_opt`). |
| **n_curves** | Integer | `9` | Number of keywords to visualize. Must be a perfect square for optimal grid layout (e.g., 4, 9, 16, 25). |
| **show_zone** | Logical | `FALSE` | If `TRUE`, includes the keyword's frequency zone in plot titles (e.g., "algorithm [Zone 4]"). |
| **graph** | Logical | `FALSE` | If `TRUE`, displays plots immediately in the R graphics device. If `FALSE` (default), plots are returned invisibly and can be accessed from the output list. |

---

## üì¶ Output

Returns (invisibly) a **list** containing visualization objects:

| Element | Type | Description |
|---------|------|-------------|
| **singleKeywordPlot** | list | A list of individual `ggplot2` objects, one for each selected keyword. Each plot shows raw (dashed) and smoothed (solid) curves with keyword name in title. |
| **combinedKeywordPlot** | patchwork | A combined grid layout displaying all selected keyword plots together. Uses `patchwork` package for arrangement. |

**Plot characteristics:**
- **Grey dashed line**: Raw frequency trajectory
- **Red solid line**: Smoothed spline fit
- **X-axis**: Time periods (years)
- **Y-axis**: Frequency (raw or normalized, depending on input data)
- **Title**: Keyword name (and zone if `show_zone = TRUE`)

---

## üí° Usage Examples

### Basic Usage

```r
library(cccc)

# Complete workflow
corpus <- importData("tdm.csv", "corpus_info.csv")
corpus_norm <- normalization(corpus, normty = "nc")

# Find optimal parameters
smooth_m2 <- smoothingSelection(corpus_norm, penalty_type = "m-2", plot = FALSE)
smooth_2 <- smoothingSelection(corpus_norm, penalty_type = "2", plot = FALSE)
optimal <- optimalSmoothing(list("m-2" = smooth_m2, "2" = smooth_2))

# Visualize smoothing quality
fits <- plotSuboptimalFits(corpus_norm, optimal)

# Display combined plot
fits$combinedKeywordPlot
```

### Show Individual Plots

```r
# Create plots
fits <- plotSuboptimalFits(corpus_norm, optimal, n_curves = 9)

# View first individual plot
fits$singleKeywordPlot[[1]]

# View specific keyword plot
fits$singleKeywordPlot[[5]]

# Save individual plots
library(ggplot2)
ggsave("keyword1_fit.png", fits$singleKeywordPlot[[1]], width = 8, height = 5)
```

### Include Zone Information

```r
# Add frequency zone to titles
fits <- plotSuboptimalFits(
  corpus_norm, 
  optimal, 
  n_curves = 9,
  show_zone = TRUE
)

# Now titles show: "algorithm [Zone 4]"
fits$combinedKeywordPlot
```


### More/Fewer Keywords

```r
# Show 4 keywords (2√ó2 grid)
fits_small <- plotSuboptimalFits(corpus_norm, optimal, n_curves = 4)

# Show 16 keywords (4√ó4 grid)
fits_large <- plotSuboptimalFits(corpus_norm, optimal, n_curves = 16)

# Show 25 keywords (5√ó5 grid)
fits_xlarge <- plotSuboptimalFits(corpus_norm, optimal, n_curves = 25)
```
---

## üîç Interpreting the Plots

### What to Look For

#### ‚úÖ **Good Smoothing**
```
Raw:     ‚Ä¢ ‚Ä¢ ‚Ä¢  ‚Ä¢  ‚Ä¢
           ‚ï±‚ï≤  ‚ï±‚ï≤
Smooth: ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  (captures trend, reduces noise)
```
- Smoothed curve follows general trend
- Reduces noise without losing important features
- No systematic bias (doesn't consistently over/underestimate)

#### ‚ö†Ô∏è **Oversmoothing**
```
Raw:     ‚Ä¢ ‚Ä¢ ‚Ä¢  ‚Ä¢  ‚Ä¢
           ‚ï±‚ï≤‚ï±‚ï≤‚ï±‚ï≤
Smooth: ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ (too flat)
```
- Smoothed curve misses important peaks or valleys
- Trajectory appears unnaturally flat
- Real patterns are suppressed

#### ‚ö†Ô∏è **Undersmoothing**
```
Raw:     ‚Ä¢ ‚Ä¢ ‚Ä¢  ‚Ä¢  ‚Ä¢
           ‚ï±‚ï≤‚ï±‚ï≤‚ï±‚ï≤
Smooth:   ‚ï±‚ï≤‚ï±‚ï≤‚ï±‚ï≤  (too wiggly)
```
- Smoothed curve follows noise too closely
- Trajectory has spurious fluctuations
- Fails to reveal underlying trend

#### ‚ö†Ô∏è **Systematic Bias**
```
Raw:     ‚Ä¢ ‚Ä¢ ‚Ä¢  ‚Ä¢  ‚Ä¢
         ‚ï±‚ï≤‚ï±‚ï≤‚ï±‚ï≤
Smooth: ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ (consistently below/above)
```
- Smoothed curve consistently over- or underestimates
- May indicate inappropriate penalty or normalization

---

## üìä Understanding the Selection

### RMS Distribution Sampling

If you have 1000 keywords and request `n_curves = 9`, the function:

1. **Computes RMS** for all 1000 keywords
2. **Sorts** keywords by RMS (low to high)
3. **Samples** 9 keywords evenly across the distribution:
   - Keywords ~1, 125, 250, 375, 500, 625, 750, 875, 1000

This gives you:
- **Low RMS keywords**: Best-fit cases (smooth, predictable)
- **Medium RMS keywords**: Typical cases (moderate complexity)
- **High RMS keywords**: Challenging cases (noisy, volatile)

### Why This Matters

Seeing only low-RMS keywords would give false confidence. Seeing only high-RMS keywords would be unnecessarily discouraging. The representative sample shows you the **realistic range** of smoothing performance.

---

## üìà Use Cases

### 1. **Quality Assurance**
Before applying smoothing to full corpus, verify it works well.

### 2. **Parameter Validation**
Confirm that `optimalSmoothing()` choices are actually optimal visually.

### 3. **Method Comparison**
Compare smoothing with different parameters side-by-side.

### 4. **Publication Figures**
Create figures showing smoothing effectiveness for methods sections.

### 5. **Identifying Outliers**
Find keywords with unusual temporal patterns that need special attention.

### 6. **Training Examples**
Show collaborators/reviewers how smoothing works on your data.

---

## üí° Tips & Best Practices

1. **Always run this function** ‚Äî Don't skip visual validation
2. **Use perfect squares** for n_curves (4, 9, 16, 25) for clean grid layouts
3. **Start with 9** ‚Äî Good balance between coverage and readability
4. **Check high-RMS cases** ‚Äî If they look terrible, reconsider parameters
5. **Save the plots** ‚Äî Include in supplementary materials or methods sections
6. **Show to colleagues** ‚Äî Get feedback on whether smoothing looks reasonable
7. **Don't expect perfection** ‚Äî Some keywords will always be noisy
8. **Compare normalizations** ‚Äî Try different normalization methods if smoothing looks poor

---

## üìö See Also

- [`optimalSmoothing()`](optimalSmoothing.html) ‚Äî Select parameters (prerequisite for this function)
- [`smoothingSelection()`](smoothingSelection.html) ‚Äî Find optimal Œª for penalties
- [`curvePlot()`](curvePlot.html) ‚Äî Visualize specific keyword trajectories
- [`facetPlot()`](facetPlot.html) ‚Äî Create faceted visualizations by zone

---

